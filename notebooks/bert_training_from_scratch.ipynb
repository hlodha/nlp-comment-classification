{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for seamlessly running on colab\n",
    "import os\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.environ[\"IS_COLAB\"] = \"True\"\n",
    "except ImportError:\n",
    "    os.environ[\"IS_COLAB\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ \"$IS_COLAB\" = \"True\" ]; then\n",
    "    pip install git+https://github.com/facebookresearch/fastText.git\n",
    "    pip install torch\n",
    "    pip install torchvision\n",
    "    pip install --upgrade git+https://github.com/keitakurita/allennlp@develop\n",
    "    pip install dnspython\n",
    "    pip install jupyter_slack\n",
    "    pip install git+https://github.com/keitakurita/Better_LSTM_PyTorch.git\n",
    "    if [ -d \"apex\" ]; then\n",
    "      git clone https://github.com/NVIDIA/apex.git\n",
    "    fi\n",
    "    cd apex && python setup.py install --cpp_ext --cuda_ext\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from overrides import overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "import functools\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "def get_ref_free_exc_info():\n",
    "    \"Free traceback from references to locals/globals to avoid circular reference leading to gc.collect() unable to reclaim memory\"\n",
    "    type, val, tb = sys.exc_info()\n",
    "    traceback.clear_frames(tb)\n",
    "    return (type, val, tb)\n",
    "\n",
    "def gpu_mem_restore(func):\n",
    "    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            type, val, tb = get_ref_free_exc_info() # must!\n",
    "            raise type(val).with_traceback(tb) from None\n",
    "    return wrapper\n",
    "\n",
    "def ifnone(a: Any, alt: Any): return alt if a is None else a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for papermill\n",
    "testing = False\n",
    "debugging = False\n",
    "seed = 1\n",
    "char_encoder = \"cnn\"\n",
    "tie_weights = False\n",
    "computational_batch_size = 8\n",
    "batch_size = 32\n",
    "loss = \"is\"\n",
    "num_neg_samples = 1280\n",
    "lr = 1e-4\n",
    "lr_schedule = \"slanted_triangular\"\n",
    "epochs = 1\n",
    "hidden_sz = 128\n",
    "num_attention_heads = 4\n",
    "num_hidden_layers = 6\n",
    "dataset = \"jigsaw_ext\"\n",
    "hashed_vocab = True\n",
    "softmax = \"cnn_softmax\"\n",
    "denoise = True\n",
    "put_embeddings_on_gpu = True\n",
    "n_classes = 6\n",
    "max_seq_len = 128\n",
    "download_data = False\n",
    "ft_model_path = \"../data/jigsaw/ft_model.txt\"\n",
    "max_vocab_size = 500000\n",
    "num_buckets = 500_000 # TODO: add to configurable parameters\n",
    "min_freq = 3\n",
    "dropouti = 0.2\n",
    "dropoutw = 0.0\n",
    "dropoute = 0.2\n",
    "dropoutr = 0.3 # TODO: Implement\n",
    "val_ratio = 0.0\n",
    "use_augmented = False\n",
    "freeze_embeddings = True\n",
    "mixup_ratio = 0.0\n",
    "discrete_mixup_ratio = 0.0\n",
    "attention_bias = True\n",
    "weight_decay = 0.\n",
    "bias_init = True\n",
    "neg_splits = 1\n",
    "num_layers = 2\n",
    "rnn_type = \"lstm\"\n",
    "pooling_type = \"augmented_multipool\" # attention or multipool or augmented_multipool\n",
    "model_type = \"standard\"\n",
    "use_word_level_features = False\n",
    "use_sentence_level_features = False\n",
    "bucket = True\n",
    "compute_thres_on_test = True\n",
    "find_lr = False\n",
    "permute_sentences = False\n",
    "construct_vocab = False\n",
    "mask_rate = 0.15\n",
    "run_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Can we make this play better with papermill?\n",
    "config = Config(\n",
    "    testing=testing,\n",
    "    debugging=debugging,\n",
    "    seed=seed,\n",
    "    char_encoder=char_encoder,\n",
    "    tie_weights=tie_weights,\n",
    "    computational_batch_size=computational_batch_size,\n",
    "    batch_size=batch_size,\n",
    "    loss=loss,\n",
    "    num_neg_samples=num_neg_samples,\n",
    "    lr=lr,\n",
    "    lr_schedule=lr_schedule,\n",
    "    epochs=epochs,\n",
    "    hidden_sz=hidden_sz,\n",
    "    num_attention_heads=num_attention_heads,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    dataset=dataset,\n",
    "    hashed_vocab=hashed_vocab,\n",
    "    softmax=softmax,\n",
    "    denoise=denoise,\n",
    "    put_embeddings_on_gpu=put_embeddings_on_gpu,\n",
    "    n_classes=n_classes,\n",
    "    max_seq_len=max_seq_len, # necessary to limit memory usage\n",
    "    ft_model_path=ft_model_path,\n",
    "    max_vocab_size=max_vocab_size,\n",
    "    num_buckets=num_buckets,\n",
    "    min_freq=min_freq,\n",
    "    dropouti=dropouti,\n",
    "    dropoutw=dropoutw,\n",
    "    dropoute=dropoute,\n",
    "    dropoutr=dropoutr,\n",
    "    val_ratio=val_ratio,\n",
    "    use_augmented=use_augmented,\n",
    "    freeze_embeddings=freeze_embeddings,\n",
    "    attention_bias=attention_bias,\n",
    "    weight_decay=weight_decay,\n",
    "    bias_init=bias_init,\n",
    "    neg_splits=neg_splits,\n",
    "    num_layers=num_layers,\n",
    "    rnn_type=rnn_type,\n",
    "    pooling_type=pooling_type,\n",
    "    model_type=model_type,\n",
    "    use_word_level_features=use_word_level_features,\n",
    "    use_sentence_level_features=use_sentence_level_features,\n",
    "    mixup_ratio=mixup_ratio,\n",
    "    discrete_mixup_ratio=discrete_mixup_ratio,\n",
    "    bucket=bucket,\n",
    "    compute_thres_on_test=compute_thres_on_test,\n",
    "    permute_sentences=permute_sentences,\n",
    "    find_lr=find_lr,\n",
    "    construct_vocab=construct_vocab,\n",
    "    mask_rate=mask_rate,\n",
    "    run_id=run_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "T = TypeVar(\"T\")\n",
    "TensorDict = Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]  # pylint: disable=invalid-name\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.nn import util as nn_util\n",
    "from allennlp.data.dataset_readers import DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ[\"IS_COLAB\"] != \"True\":\n",
    "    DATA_ROOT = Path(\"../data\") / config.dataset\n",
    "else:\n",
    "    DATA_ROOT = Path(\"./gdrive/My Drive/Colab_Workspace/Colab Notebooks/data\") / config.dataset\n",
    "    config.ft_model_path = str(DATA_ROOT / \"ft_model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "if download_data:\n",
    "    if config.val_ratio > 0.0:\n",
    "        fnames = [\"train_wo_val.csv\", \"test_proced.csv\", \"val.csv\", \"ft_model.txt\"]\n",
    "    else:\n",
    "        fnames = [\"train.csv\", \"test_proced.csv\", \"ft_model.txt\"]\n",
    "    if config.use_augmented or config.discrete_mixup_ratio > 0.0: fnames.append(\"train_extra.csv\")\n",
    "    for fname in fnames:\n",
    "        if not (DATA_ROOT / fname).exists():\n",
    "            print(subprocess.Popen([f\"aws s3 cp s3://nnfornlp/raw_data/jigsaw/{fname} {str(DATA_ROOT)}\"],\n",
    "                                   shell=True, stdout=subprocess.PIPE).stdout.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.fields import (TextField, SequenceLabelField, LabelField, \n",
    "                                  MetadataField, ArrayField)\n",
    "\n",
    "class MemoryOptimizedTextField(TextField):\n",
    "    @overrides\n",
    "    def __init__(self, tokens: List[str], token_indexers: Dict[str, TokenIndexer]) -> None:\n",
    "        self.tokens = tokens\n",
    "        self._token_indexers = token_indexers\n",
    "        self._indexed_tokens: Optional[Dict[str, TokenList]] = None\n",
    "        self._indexer_name_to_indexed_token: Optional[Dict[str, List[str]]] = None\n",
    "        # skip checks for tokens\n",
    "    @overrides\n",
    "    def index(self, vocab):\n",
    "        super().index(vocab)\n",
    "    \n",
    "    def deindex(self):\n",
    "        self._indexed_tokens = None\n",
    "        self._indexer_name_to_indexed_token = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawLMDatasetReader(DatasetReader):\n",
    "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer]=None, # TODO: Handle mapping from BERT\n",
    "                 output_token_indexers: Dict[str, TokenIndexer]=None,\n",
    "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers\n",
    "        self.output_token_indexers = output_token_indexers or token_indexers\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def _clean(self, x: str) -> str:\n",
    "        \"\"\"\n",
    "        Maps a word to its desired output. Will leave as identity for now.\n",
    "        In the future, will change to denoising operation.\n",
    "        \"\"\"\n",
    "        return x\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[str]) -> Instance:\n",
    "        sentence_field = MemoryOptimizedTextField(\n",
    "            [x for x in tokens],\n",
    "            self.token_indexers)\n",
    "        fields = {\"input\": sentence_field}\n",
    "        output_sentence_field = MemoryOptimizedTextField(\n",
    "            [self._clean(x) for x in tokens],\n",
    "            self.output_token_indexers)\n",
    "        fields[\"output\"] = output_sentence_field\n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if config.testing: df = df.head(1000)\n",
    "        for i, row in df.iterrows():\n",
    "            yield self.text_to_instance(\n",
    "                self.tokenizer(row[\"comment_text\"]),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "class JigsawDenoiseDatasetReader(DatasetReader):\n",
    "    def __init__(self,\n",
    "                 lazy: bool=True,\n",
    "                 tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer]=None, # TODO: Handle mapping from BERT\n",
    "                 output_token_indexers: Dict[str, TokenIndexer]=None,\n",
    "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
    "        super().__init__(lazy=lazy)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers\n",
    "        self.output_token_indexers = output_token_indexers or token_indexers\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[str], noise_tokens: List[str]) -> Instance:\n",
    "        sentence_field = MemoryOptimizedTextField(\n",
    "            [x for x in noise_tokens],\n",
    "            self.token_indexers)\n",
    "        fields = {\"input\": sentence_field}\n",
    "        output_sentence_field = MemoryOptimizedTextField(\n",
    "            [x for x in tokens],\n",
    "            self.output_token_indexers)\n",
    "        fields[\"output\"] = output_sentence_field\n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        with open(file_path) as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for i, line in enumerate(reader):\n",
    "                if config.testing and i == 1000: break\n",
    "                id_, text, noised_text = line\n",
    "                text = self.tokenizer(text)\n",
    "                noised_text = self.tokenizer(noised_text)\n",
    "                assert len(text) == len(noised_text)\n",
    "                yield self.text_to_instance(\n",
    "                    text, noised_text,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebbaseReader(DatasetReader):\n",
    "    def __init__(self,\n",
    "                 lazy: bool=True,\n",
    "                 tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer]=None, # TODO: Handle mapping from BERT\n",
    "                 output_token_indexers: Dict[str, TokenIndexer]=None,\n",
    "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
    "        super().__init__(lazy=lazy)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers\n",
    "        self.output_token_indexers = output_token_indexers or token_indexers\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[str], noise_tokens: List[str]) -> Instance:\n",
    "        sentence_field = MemoryOptimizedTextField(\n",
    "            [x for x in noise_tokens],\n",
    "            self.token_indexers)\n",
    "        fields = {\"input\": sentence_field}\n",
    "        output_sentence_field = MemoryOptimizedTextField(\n",
    "            [x for x in tokens],\n",
    "            self.output_token_indexers)\n",
    "        fields[\"output\"] = output_sentence_field\n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        with open(file_path) as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "            for i, line in enumerate(reader):\n",
    "                if config.testing and i == 1000: break\n",
    "                try:\n",
    "                    text, noised_text = line\n",
    "                except:\n",
    "                    continue\n",
    "                text = self.tokenizer(text)\n",
    "                noised_text = self.tokenizer(noised_text)\n",
    "                assert len(text) == len(noised_text)\n",
    "                yield self.text_to_instance(\n",
    "                    text, noised_text,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_repeats(s, max_reps=2):\n",
    "    last_char = None\n",
    "    last_char_count = 0\n",
    "    new_s = \"\"\n",
    "    for c in s:\n",
    "        if c == last_char:\n",
    "            if last_char_count >= max_reps:\n",
    "                continue\n",
    "            else:\n",
    "                new_s += c\n",
    "                last_char_count += 1\n",
    "        else:\n",
    "            last_char = c\n",
    "            last_char_count = 1\n",
    "            new_s += c\n",
    "    return new_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "\n",
    "if config.char_encoder == \"cnn\":\n",
    "    token_indexer = ELMoTokenCharactersIndexer()\n",
    "else:\n",
    "    token_indexer = SingleIdTokenIndexer(\n",
    "        lowercase_tokens=config.softmax != \"cnn_softmax\") # Temporary\n",
    "\n",
    "_spacy_tok = SpacyWordSplitter(language='en_core_web_sm', pos_tags=False).split_words\n",
    "\n",
    "\n",
    "url_ptrn = re.compile(\"https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+\")\n",
    "def proc(x):\n",
    "    x = x.lower()\n",
    "    x = url_ptrn.sub(\"url\", x)\n",
    "    x = replace_repeats(x)\n",
    "    return x\n",
    "\n",
    "if config.denoise:\n",
    "    def tokenizer(x: str):\n",
    "        return [\"[CLS]\"] + [proc(w) for w in\n",
    "                x.split()[:config.max_seq_len - 2]] + [\"[SEP]\"]\n",
    "else:\n",
    "    _spacy_tok = SpacyWordSplitter(language='en_core_web_sm', pos_tags=False).split_words\n",
    "    def tokenizer(x: str):\n",
    "        return [\"[CLS]\"] + [proc(w.text) for w in\n",
    "                _spacy_tok(x)[:config.max_seq_len - 2]] + [\"[SEP]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.loss == \"is\" and config.softmax == \"cnn_softmax\" and not config.construct_vocab:\n",
    "    output_token_indexer = token_indexer\n",
    "else:\n",
    "    output_token_indexer = SingleIdTokenIndexer(lowercase_tokens=True)\n",
    "\n",
    "input_token_indexers = {\"tokens\": token_indexer}\n",
    "\n",
    "if config.dataset == \"jigsaw\":\n",
    "    if config.denoise:\n",
    "        reader = JigsawDenoiseDatasetReader(\n",
    "            tokenizer=tokenizer,\n",
    "            token_indexers=input_token_indexers,\n",
    "            output_token_indexers={\"tokens\": output_token_indexer}\n",
    "        )\n",
    "        train_ds, val_ds, test_ds = (reader.read(DATA_ROOT / fname) for fname in [\n",
    "            \"train_side_by_side.csv\",\n",
    "            \"val_side_by_side.csv\",\n",
    "            \"val_side_by_side.csv\",\n",
    "        ])\n",
    "    else:\n",
    "        reader = JigsawLMDatasetReader(\n",
    "            tokenizer=tokenizer,\n",
    "            token_indexers=input_token_indexers,\n",
    "            output_token_indexers={\"tokens\": output_token_indexer}\n",
    "        )\n",
    "        train_ds, val_ds, test_ds = (reader.read(DATA_ROOT / fname) for fname in [\"train_wo_val.csv\",\n",
    "                                                                                  \"val.csv\",\n",
    "                                                                                  \"test_proced.csv\"])\n",
    "elif config.dataset == \"webbase\":\n",
    "    assert config.hashed_vocab or config.char_encoder == \"cnn\"\n",
    "    assert config.denoise\n",
    "    if config.denoise:\n",
    "        reader = WebbaseReader(\n",
    "            tokenizer=tokenizer,\n",
    "            token_indexers=input_token_indexers,\n",
    "            output_token_indexers={\"tokens\": output_token_indexer}\n",
    "        )\n",
    "        train_ds = (reader.read(DATA_ROOT / \"all_denoise.txt\"))\n",
    "        val_ds = None\n",
    "elif config.dataset == \"jigsaw_ext\":\n",
    "    assert config.denoise\n",
    "    reader = JigsawDenoiseDatasetReader(\n",
    "            tokenizer=tokenizer,\n",
    "            token_indexers=input_token_indexers,\n",
    "            output_token_indexers={\"tokens\": output_token_indexer}\n",
    "        )\n",
    "    train_ds = reader.read(DATA_ROOT / \"train_denoise.csv\")\n",
    "    val_ds = None\n",
    "else:\n",
    "    raise ValueError(f\"Invalid dataset {config.dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnv\n",
    "class HashedVocabulary(Vocabulary):\n",
    "    def __init__(self, *args, \n",
    "                 protected={\"[pad]\": 0, \"[cls]\": 2, \"[sep]\": 3, \"[MASK]\": 1},\n",
    "                 num_buckets=config.num_buckets,\n",
    "                 **kwargs,\n",
    "                ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.protected = protected\n",
    "        self.num_buckets = (num_buckets - len(self.protected))\n",
    "        \n",
    "    def get_token_index(self, w, namespace=\"tokens\"):\n",
    "        if w in self.protected: return self.protected[w]\n",
    "        else:\n",
    "            hash_val = fnv.hash(w.encode(\"utf-8\"), bits=32)\n",
    "            return (hash_val % self.num_buckets) + len(self.protected)\n",
    "    \n",
    "    def get_vocab_size(self, namespace=\"tokens\"):\n",
    "        if \"char\" not in namespace: return self.num_buckets + len(self.protected)\n",
    "        else: raise ValueError(f\"{namespace} is not a valid namespace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.hashed_vocab and not config.char_encoder == \"cnn\":\n",
    "    vocab = HashedVocabulary()\n",
    "else:\n",
    "    if config.construct_vocab:\n",
    "        full_ds = train_ds + test_ds + val_ds\n",
    "        vocab = Vocabulary.from_instances(full_ds, tokens_to_add={\"tokens\": [\"[MASK]\"]},\n",
    "                                          min_count={\"tokens\": 2},\n",
    "                                          max_vocab_size=config.max_vocab_size)\n",
    "        vocab.save_to_files(DATA_ROOT / \"bert_vocab\")\n",
    "    else:\n",
    "        vocab = Vocabulary.from_files(DATA_ROOT / \"bert_vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98251"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_vocab_size(\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Implement fast sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.loss == \"is\":\n",
    "    if config.construct_vocab:\n",
    "        freqs = np.zeros(vocab.get_vocab_size())\n",
    "        for w, c in vocab._retained_counter[\"tokens\"].items():\n",
    "            freqs[vocab.get_token_index(w)] = c\n",
    "        freqs /= freqs.sum()\n",
    "        freqs **= 2 / 3\n",
    "        # renormalize\n",
    "        freqs /= freqs.sum()\n",
    "        np.save(DATA_ROOT / \"bert_vocab_counts.npy\", freqs)\n",
    "    else:\n",
    "        freqs = np.load(DATA_ROOT / \"..\" / \"jigsaw\" / \"bert_vocab_counts.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set(\"vocab_sz\", vocab.get_vocab_size(\"tokens\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98251"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.vocab_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert config.vocab_sz == freqs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BucketIterator, DataIterator, BasicIterator, MemoryOptimizedIterator\n",
    "if config.bucket:\n",
    "    iterator = BucketIterator(\n",
    "            batch_size=config.computational_batch_size, \n",
    "            biggest_batch_first=config.testing,\n",
    "            sorting_keys=[(\"input\", \"num_tokens\")],\n",
    "            max_instances_in_memory=config.batch_size * 2,\n",
    "    )\n",
    "else:\n",
    "    iterator = MemoryOptimizedIterator(\n",
    "        batch_size=config.computational_batch_size,\n",
    "        max_instances_in_memory=config.batch_size * 2,\n",
    "    )\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterator(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(261)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input\"][\"tokens\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build word to indices mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Output this constructed dictionary to disk and load in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnv\n",
    "def fnv_hash(w):\n",
    "    return fnv.hash(w.encode(\"utf-8\"), bits=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_char_ngrams(w, range_=range(2, 6)):\n",
    "    w = \"<\" + w + \">\"\n",
    "    for r in range_: # prioritize smaller n-grams\n",
    "        for i, c in enumerate(w):\n",
    "            if i + r <= len(w): yield w[i:i+r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98251/98251 [00:00<00:00, 192921.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Building character indexes] done in 1 s\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "if config.char_encoder == \"cnn\":\n",
    "    # TODO: Speed up\n",
    "    # TODO: Debug\n",
    "    # See allennlp/data/token_indexers/elmo_indexer.py\n",
    "    with timer(\"Building character indexes\"):\n",
    "        word_id_to_char_idxs = np.zeros((config.vocab_sz, 50))\n",
    "        for w, idx in tqdm(vocab.get_token_to_index_vocabulary().items()):\n",
    "            # TODO: Check for start/end of word symbols\n",
    "            if idx > 0: \n",
    "                word_id_to_char_idxs[idx, :] = 261\n",
    "                word_id_to_char_idxs[idx, 0] = 259\n",
    "                for i, c in enumerate(w.encode(\"utf-8\")):\n",
    "                    if i + 1 == 48: break\n",
    "                    word_id_to_char_idxs[idx, i+1] = int(c) + 1\n",
    "                word_id_to_char_idxs[idx, i+2] = 260\n",
    "        word_id_to_char_idxs = np.array(word_id_to_char_idxs)\n",
    "\n",
    "    word_id_to_char_idxs = torch.LongTensor(word_id_to_char_idxs).to(device)\n",
    "elif config.char_encoder == \"subword\":\n",
    "    word_to_uid = {}\n",
    "    uid = 2 # reserve @@PADDING@@ and @@UNKNOWN@@\n",
    "    for word, freq in tqdm(vocab._retained_counter[\"tokens\"].items()):\n",
    "        if freq > config.min_freq:\n",
    "            word_to_uid[word] = uid; uid += 1\n",
    "        else:\n",
    "            word_to_uid[word] = -1\n",
    "    num_uniq_ids = uid\n",
    "    offset = num_uniq_ids # these slots are reserved for unique words in the embedding matrix\n",
    "    with timer(\"Building word to subword indices mapping\"):\n",
    "        subword_ids = [[] for _ in vocab.get_token_to_index_vocabulary()]\n",
    "        freq_counter = vocab._retained_counter[\"tokens\"]\n",
    "        for word, idx in tqdm(vocab.get_token_to_index_vocabulary().items()):\n",
    "            if word == \"@@PADDING@@\" or word == \"@@UNKNOWN@@\" or word == \"[MASK]\":\n",
    "                subword_ids[idx] = [idx]\n",
    "            else:\n",
    "                uid = word_to_uid[word]\n",
    "                uniq_idx = [uid] if uid > -1 else [] # only give unique index to words with sufficient frequency\n",
    "                subword_ids[idx] = uniq_idx + list([fnv_hash(x) % config.num_buckets + offset\n",
    "                                                    for x in generate_char_ngrams(word)])\n",
    "        maxlen = int(np.percentile([len(a) for a in subword_ids], 95)) # 95th-percentile\n",
    "        word_id_to_subword_ids = torch.zeros(len(subword_ids), maxlen, dtype=torch.long)\n",
    "        word_id_to_num_subwords = torch.zeros(len(subword_ids), 1, dtype=torch.float)\n",
    "        print(word_id_to_subword_ids.shape)\n",
    "        for i, idxs in tqdm(enumerate(subword_ids)):\n",
    "            for j, id_ in enumerate(idxs):\n",
    "                if j >= maxlen: break\n",
    "                word_id_to_subword_ids[i, j] = id_\n",
    "            word_id_to_num_subwords[i] = len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [259,  65,  65,  86,  79,  76,  79,  80,  88,  79,  65,  65, 260, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261],\n",
       "        [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261],\n",
       "        [259, 117, 105, 102, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261],\n",
       "        [259,  45, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261],\n",
       "        [259,  35, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261],\n",
       "        [259, 117, 112, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261],\n",
       "        [259, 106, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261],\n",
       "        [259,  92, 100, 109, 116,  94, 260, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261],\n",
       "        [259,  92, 116, 102, 113,  94, 260, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "         261, 261, 261, 261, 261, 261, 261, 261]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_id_to_char_idxs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"cnn\":\n",
    "    mask_char_ids = torch.ones(50, dtype=torch.int64).to(device) * 261\n",
    "    for i, c in enumerate(\"[MASK]\".encode(\"utf-8\")):\n",
    "        mask_char_ids[i+1] = int(c) + 1\n",
    "    mask_char_ids[i+2] = 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 128,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 512,\n",
       "  \"max_position_embeddings\": 128,\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 500000\n",
       "}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_pretrained_bert.modeling import (BertConfig, BertForMaskedLM, \n",
    "                                              BertEncoder, BertPooler, BertOnlyMLMHead)\n",
    "\n",
    "bert_config = BertConfig(\n",
    "        config.max_vocab_size, \n",
    "        hidden_size=config.hidden_sz, \n",
    "        num_attention_heads=config.num_attention_heads,\n",
    "        num_hidden_layers=config.num_hidden_layers, \n",
    "        intermediate_size=config.hidden_sz * config.num_attention_heads,\n",
    "        max_position_embeddings=config.max_seq_len,\n",
    ")\n",
    "\n",
    "bert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building token embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"cnn\":\n",
    "    from allennlp.modules.token_embedders.elmo_token_embedder import ElmoTokenEmbedder\n",
    "    from allennlp.modules.elmo import _ElmoCharacterEncoder\n",
    "\n",
    "    options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
    "    weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
    "    _inner_char_encoder = _ElmoCharacterEncoder(\n",
    "        options_file=options_file, \n",
    "        weight_file=weight_file,\n",
    "        requires_grad=True\n",
    "    )\n",
    "    class ElmoEncoder(nn.Module):\n",
    "        def __init__(self, _inner):\n",
    "            super().__init__()\n",
    "            self._inner = _inner\n",
    "        def forward(self, *args):\n",
    "            # TODO: Stop Elmo encoder from adding SoS and EoS tokens\n",
    "            return self._inner(*args)[\"token_embedding\"][:, 1:-1, :]\n",
    "        def get_output_dim(self):\n",
    "            return self._inner.get_output_dim()\n",
    "    char_encoder = ElmoEncoder(_inner_char_encoder)\n",
    "\n",
    "# char_encoder\n",
    "\n",
    "# sample_idxs = next(iterator(train_ds))[\"tokens\"][\"tokens\"]\n",
    "\n",
    "# char_encoder(sample_idxs)\n",
    "    config.set(\"embedding_sz\", char_encoder.get_output_dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of char-ngrams using fastText (too much memory consumption for now...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.sparse import EmbeddingBag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"subword\":\n",
    "    from torch.nn.modules.sparse import EmbeddingBag\n",
    "    \n",
    "    # A hack to prevent these embeddings from being put on the GPU\n",
    "    global_emb_bag = EmbeddingBag(offset + config.num_buckets, 250, mode=\"sum\")\n",
    "    if config.put_embeddings_on_gpu and torch.cuda.is_available():\n",
    "        global_emb_bag.cuda()\n",
    "\n",
    "    class SubwordEncoder(nn.Module):\n",
    "        def __init__(self, num_embeddings, \n",
    "                     embedding_sz, \n",
    "                     embeddings_on_gpu: bool=config.put_embeddings_on_gpu):\n",
    "            super().__init__()\n",
    "            self._embeddings_on_gpu = embeddings_on_gpu\n",
    "            self._device = torch.device(\"cuda:0\" if torch.cuda.is_available() and embeddings_on_gpu else \"cpu\")\n",
    "            self._subword_encoding = word_id_to_subword_ids.to(self._device)\n",
    "            self._subword_count = word_id_to_num_subwords.to(self._device)\n",
    "            self.n_subwords_per_word = self._subword_encoding.size(1)\n",
    "\n",
    "        def forward(self, \n",
    "                    tsr: torch.LongTensor, # (batch, seq) or # (batch)\n",
    "                   ) -> torch.FloatTensor: # (batch, seq, feat) or # (batch, feat)\n",
    "            # TODO: can I use offsets in a differentiable manner??\n",
    "            if len(tsr.shape) > 1:\n",
    "                bs, seq = tsr.size(0), tsr.size(1)\n",
    "                subword_ids = self._subword_encoding[tsr]\n",
    "                bag_of_embs = global_emb_bag(subword_ids.view((-1, self.n_subwords_per_word)) # need to convert to 2D\n",
    "                                      ).view((bs, seq, -1)) # reshape to 3d\n",
    "            else:\n",
    "                subword_ids = self._subword_encoding[tsr]\n",
    "                bag_of_embs = global_emb_bag(subword_ids)\n",
    "            norm_factor = self._subword_count[tsr] + 0.1\n",
    "            embs = bag_of_embs / norm_factor\n",
    "            if self._embeddings_on_gpu:\n",
    "                return embs\n",
    "            else:\n",
    "                return embs.to(device)\n",
    "    \n",
    "    char_encoder = SubwordEncoder(offset + config.num_buckets, 250)\n",
    "    config.set(\"embedding_sz\", 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElmoEncoder(\n",
       "  (_inner): _ElmoCharacterEncoder(\n",
       "    (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "    (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "    (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "    (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "    (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "    (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "    (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "    (_highways): Highway(\n",
       "      (_layers): ModuleList(\n",
       "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (_projection): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple word-level embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"fasttext\":\n",
    "    from allennlp.modules import Embedding\n",
    "\n",
    "    ft_matrix = np.random.randn(bert_config.vocab_size, 300) * 0.3\n",
    "    char_encoder = Embedding(bert_config.vocab_size, 300, weight=torch.FloatTensor(ft_matrix))\n",
    "    config.set(\"embedding_sz\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(x):\n",
    "    x.requires_grad = False\n",
    "    if hasattr(x, \"parameters\"):\n",
    "        for p in x.parameters: freeze(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-12):\n",
    "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.weight * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingWPositionEmbs(nn.Module):\n",
    "    \"\"\"Embeds, then maps the embeddings to the bert_hidden_sz for processing\"\"\"\n",
    "    def __init__(self, word_emb: nn.Module, \n",
    "                 embedding_dim,\n",
    "                 bert_hidden_sz, \n",
    "                 freeze_embeddings=False,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.word_emb = word_emb\n",
    "        if freeze_embeddings: freeze(self.word_emb)\n",
    "        self.position_embeddings = nn.Embedding(config.max_seq_len, \n",
    "                                                bert_hidden_sz)\n",
    "        self.linear = nn.Linear(embedding_dim, bert_hidden_sz,\n",
    "                                bias=False) # Transform dimensions\n",
    "        self.norm = LayerNorm(bert_hidden_sz)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "    \n",
    "    def get_word_embs(self, input_ids):\n",
    "        return self.linear(self.word_emb(input_ids))\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        # We won't be using token types since we won't be predicting the next sentence\n",
    "        bs, seq_length, *_ = input_ids.shape\n",
    "        position_ids = (torch.arange(seq_length, dtype=torch.long)\n",
    "                             .to(device)\n",
    "                             .unsqueeze(0)\n",
    "                             .expand((bs, seq_length)))\n",
    "        word_embs = self.get_word_embs(input_ids)\n",
    "        position_embs = self.position_embeddings(position_ids)\n",
    "        normed = self.norm(word_embs + position_embs)\n",
    "        return self.do(normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_embs = EmbeddingWPositionEmbs(\n",
    "    char_encoder,\n",
    "    config.embedding_sz,\n",
    "    bert_config.hidden_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): sample_embs.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nm, param in sample_embs.named_parameters():\n",
    "    if \"bag\" in nm: param.to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_encoder = BertEncoder(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBert(nn.Module):\n",
    "    def __init__(self, embeddings, encoder):\n",
    "        super().__init__()\n",
    "        self.embeddings = embeddings\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def forward(self, input_ids, \n",
    "                token_type_ids=None, \n",
    "                attention_mask=None):\n",
    "        if attention_mask is None:\n",
    "            if len(input_ids.shape) > 2:\n",
    "                attention_mask = torch.ones_like(input_ids[:, :, 0]).to(device)\n",
    "            else:\n",
    "                attention_mask = torch.ones_like(input_ids).to(device)\n",
    "        if token_type_ids is None:\n",
    "            if len(input_ids.shape) > 2:\n",
    "                token_type_ids = torch.ones_like(input_ids[:, :, 0]).to(device)\n",
    "            else:\n",
    "                token_type_ids = torch.ones_like(input_ids).to(device)\n",
    "        \n",
    "        # We create a 3D attention mask from a 2D tensor mask.\n",
    "        # Sizes are [batch_size, 1, 1, to_seq_length]\n",
    "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
    "        # this attention mask is more simple than the triangular masking of causal attention\n",
    "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "        # masked positions, this operation will create a tensor which is 0.0 for\n",
    "        # positions we want to attend and -10000.0 for masked positions.\n",
    "        # Since we are adding it to the raw scores before the softmax, this is\n",
    "        # effectively the same as removing these entirely.\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        embedding_output = self.embeddings(input_ids)\n",
    "        encoded_layers = self.encoder(embedding_output,\n",
    "                                      extended_attention_mask,\n",
    "                                      output_all_encoded_layers=True)\n",
    "        return encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertMLMPooler(nn.Module):\n",
    "    def forward(self, x: List[torch.FloatTensor]) -> torch.FloatTensor:\n",
    "        return x[-1] # return final layer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = CustomBert(sample_embs, bert_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "class BertCustomLMPredictionHead(nn.Module):\n",
    "    def __init__(self, config, out_sz, vocab_sz, \n",
    "                 embedding, output_logits=True):\n",
    "        super().__init__()\n",
    "        # Projections\n",
    "        self.dense = nn.Linear(config.hidden_size, out_sz)\n",
    "        self.transform_act_fn = gelu\n",
    "        self.LayerNorm = LayerNorm(out_sz)\n",
    "        \n",
    "        # Predictions\n",
    "        self.output_logits = output_logits\n",
    "        if self.output_logits:\n",
    "            self.decoder = nn.Linear(out_sz, vocab_sz, \n",
    "                                     bias=False)\n",
    "            if embedding is not None:\n",
    "                self.decoder.weight = embedding\n",
    "            self.bias = nn.Parameter(torch.zeros(vocab_sz))\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        if self.output_logits:\n",
    "            hidden_states = self.dense(hidden_states)\n",
    "            hidden_states = self.transform_act_fn(hidden_states)\n",
    "            preds = self.LayerNorm(hidden_states)\n",
    "            preds = self.decoder(preds) + self.bias\n",
    "        else:\n",
    "            preds = hidden_states\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_logits = config.loss != \"is\"\n",
    "bert_mlm_head = BertCustomLMPredictionHead(config=bert_config, \n",
    "                                           out_sz=config.embedding_sz, \n",
    "                                           vocab_sz=config.vocab_sz,\n",
    "                                           embedding=(sample_embs.word_emb.weight \n",
    "                                                      if config.char_encoder == \"fasttext\" \n",
    "                                                      else None),\n",
    "                                           output_logits=output_logits,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = nn.Sequential(\n",
    "    bert_model,\n",
    "    BertMLMPooler(),\n",
    "    bert_mlm_head,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoDecoder(nn.Module):\n",
    "    \"\"\"TODO: Add word correction\"\"\"\n",
    "    def __init__(self, enc: nn.Module, dec: nn.Linear, word_correction_dim: int=0):\n",
    "        super().__init__()\n",
    "        self._enc = enc\n",
    "        self._dec = dec\n",
    "        self.word_correction_dim = word_correction_dim\n",
    "        if word_correction_dim > 0:\n",
    "            self.word_correction = nn.Embedding(config.max_vocab_size,\n",
    "                                                word_correction_dim)\n",
    "            self.back_projection = nn.Linear(word_correction_dim, self._dec.out_features, \n",
    "                                             bias=False)\n",
    "        \n",
    "    def forward(self, idxs, lookup_char_idxs=True):\n",
    "        if len(idxs.shape) == 1: \n",
    "            idxs = idxs.unsqueeze(0)\n",
    "        if lookup_char_idxs:\n",
    "            char_idxs = word_id_to_char_idxs[idxs]\n",
    "        else:\n",
    "            char_idxs = idxs\n",
    "            \n",
    "        output = self._dec(self._enc(char_idxs)).squeeze(0) \n",
    "        if self.word_correction_dim > 0:\n",
    "            corr = self.back_projection(self.word_correction(idxs.squeeze(0)))\n",
    "            return output + corr\n",
    "        else: return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElmoEncoder(\n",
       "  (_inner): _ElmoCharacterEncoder(\n",
       "    (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "    (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "    (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "    (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "    (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "    (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "    (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "    (_highways): Highway(\n",
       "      (_layers): ModuleList(\n",
       "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (_projection): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embs.word_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"fasttext\":\n",
    "    output_embs = sample_embs.get_word_embs\n",
    "elif config.char_encoder == \"cnn\" and config.softmax == \"cnn_softmax\" and config.loss == \"is\":\n",
    "    if not config.tie_weights:\n",
    "        _inner_char_decoder = _ElmoCharacterEncoder(\n",
    "                options_file=options_file, \n",
    "                weight_file=weight_file,\n",
    "                requires_grad=True\n",
    "        )\n",
    "        char_decoder = ElmoEncoder(_inner_char_decoder)\n",
    "    else:\n",
    "        char_decoder = sample_embs.word_emb\n",
    "    # share just the linear transformation with \n",
    "    output_embs = ElmoDecoder(char_decoder, sample_embs.linear)\n",
    "    if torch.cuda.is_available(): output_embs.cuda()\n",
    "elif config.char_encoder == \"subword\":\n",
    "    output_embs = sample_embs.get_word_embs # tie input and output weights\n",
    "else:\n",
    "    from allennlp.modules import Embedding\n",
    "    mtrx = None\n",
    "    output_embs = Embedding(config.vocab_sz, bert_config.hidden_size, weight=mtrx)\n",
    "    if torch.cuda.is_available(): output_embs.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCorrection(nn.Module):\n",
    "    \"\"\"From the paper `Exploring the Limitations of Language Modeling`\"\"\"\n",
    "    def __init__(self, hidden_sz: int, bottleneck_sz: int=128):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(hidden_sz, bottleneck_sz)\n",
    "        \n",
    "    def forward(self, h: torch.FloatTensor, \n",
    "                corr: torch.FloatTensor):\n",
    "        x = self.l1(h)\n",
    "        return x @ corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masked Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, preds, tgts, mask=None) -> torch.tensor:\n",
    "        if mask is None:\n",
    "            return self._loss(preds, tgts).mean()\n",
    "        else:\n",
    "            # Is this reshaping really necessary? Seems like there would be a more elegant solution\n",
    "            loss = self._loss(preds.view((-1, preds.size(-1))),\n",
    "                              tgts.view((-1, )))\n",
    "            n_elements = mask.sum()\n",
    "            return (loss * mask.view((-1, )).float()).sum() / n_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformSampler:\n",
    "    def __init__(self, min_, max_):\n",
    "        self.min_, self.max_ = min_, max_\n",
    "    \n",
    "    def sample(self, shape):\n",
    "        return torch.randint(low=self.min_,\n",
    "                             high=self.max_, size=shape)\n",
    "\n",
    "class UnigramSampler:\n",
    "    def __init__(self, probs):\n",
    "        self.probs = probs\n",
    "    @staticmethod\n",
    "    def _prod(x):\n",
    "        acc = 1\n",
    "        for a in x: acc *= a\n",
    "        return acc\n",
    "    def sample(self, shape):\n",
    "        return torch.multinomial(self.probs, self._prod(shape), replacement=True).view(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportanceSamplingLoss(nn.Module):\n",
    "    def __init__(self, embedding_generator,\n",
    "                 probs: np.ndarray, k=config.num_neg_samples):\n",
    "        super().__init__()\n",
    "        self.embedding_generator = embedding_generator\n",
    "        # TODO: Should this be according to the unigram probability?\n",
    "        # Or should it be uniform?\n",
    "        self.sampler = UnigramSampler(probs=torch.FloatTensor(probs))\n",
    "        # TODO: Compute samples in advance\n",
    "        self._loss_func = MaskedCrossEntropyLoss()\n",
    "        self.k = k\n",
    "    \n",
    "    def get_negative_samples(self) -> torch.LongTensor:\n",
    "        neg = self.sampler.sample((self.k, )) # TODO: Speed up??\n",
    "        return neg\n",
    "    \n",
    "    def get_embeddings(self, idxs: torch.LongTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Converts indexes into vectors\"\"\"\n",
    "        return self.embedding_generator(idxs) # TODO: Implement general case\n",
    "    \n",
    "    def forward(self, y: torch.LongTensor, tgt, mask=None):\n",
    "        \"\"\"\n",
    "        Expects input of shape\n",
    "        y: (batch * seq, feature_sz)\n",
    "        tgt: (batch * seq, )\n",
    "        \"\"\"\n",
    "        if len(y.shape) > 2:            \n",
    "            y = y.view((-1, y.size(-1))) # (batch * seq, emb_sz)\n",
    "            tgt = tgt.view((-1, )) # (batch * seq, s)\n",
    "        bs, emb_sz = y.size(0), y.size(1)\n",
    "        pos_embeddings = self.get_embeddings(tgt) # (bs, emb_sz)\n",
    "        # share negative samples across the batch\n",
    "        neg_samples = (self.get_negative_samples()\n",
    "                       .to(y.device)) # (k, )\n",
    "        neg_embeddings = self.get_embeddings(neg_samples) # (k, emb_sz)\n",
    "        embs = torch.cat([\n",
    "            pos_embeddings.unsqueeze(1), # (bs, 1, emb_sz)\n",
    "            neg_embeddings.unsqueeze(0).expand(bs, self.k, emb_sz) # (bs, k, emb_sz)\n",
    "        ], dim=1) # (bs, k+1, emb_sz)\n",
    "        dot_prods = torch.einsum(\"bkf,bf->bk\", embs, y)\n",
    "        return self._loss_func(dot_prods, torch.zeros(bs, dtype=torch.int64).to(y.device),\n",
    "                               mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportanceSamplingCNNLoss(nn.Module):\n",
    "    def __init__(self, embedding_generator,\n",
    "                 probs: np.ndarray, k=config.num_neg_samples):\n",
    "        super().__init__()\n",
    "        self.embedding_generator = embedding_generator\n",
    "        # TODO: Should this be according to the unigram probability?\n",
    "        # Or should it be uniform?\n",
    "        self.sampler = UnigramSampler(probs=torch.FloatTensor(probs))\n",
    "        # TODO: Compute samples in advance\n",
    "        self._loss_func = MaskedCrossEntropyLoss()\n",
    "        self.k = k\n",
    "    \n",
    "    def get_negative_samples(self) -> torch.LongTensor:\n",
    "        neg = self.sampler.sample((self.k, )) # TODO: Speed up??\n",
    "        return neg\n",
    "    \n",
    "    def get_embeddings(self, idxs: torch.LongTensor, **kwargs) -> torch.FloatTensor:\n",
    "        \"\"\"Converts indexes into vectors\"\"\"\n",
    "        return self.embedding_generator(idxs, **kwargs) # TODO: Implement general case\n",
    "    \n",
    "    def forward(self, y: torch.LongTensor, tgt, mask=None):\n",
    "        \"\"\"\n",
    "        Expects input of shape\n",
    "        y: (batch * seq, feature_sz)\n",
    "        tgt: (batch * seq, chars)\n",
    "        \"\"\"\n",
    "        if len(y.shape) > 2:            \n",
    "            y = y.view((-1, y.size(-1))) # (batch * seq, emb_sz)\n",
    "        bs, emb_sz = y.size(0), y.size(1)\n",
    "        pos_embeddings = self.get_embeddings(tgt, lookup_char_idxs=False).view(bs, -1) # (bs, emb_sz)\n",
    "        # share negative samples across the batch\n",
    "        neg_samples = (self.get_negative_samples()\n",
    "                       .to(y.device)) # (k, )\n",
    "        neg_embeddings = self.get_embeddings(neg_samples) # (k, emb_sz)\n",
    "        embs = torch.cat([\n",
    "            pos_embeddings.unsqueeze(1), # (bs, 1, emb_sz)\n",
    "            neg_embeddings.unsqueeze(0).expand(bs, self.k, emb_sz) # (bs, k, emb_sz)\n",
    "        ], dim=1) # (bs, k+1, emb_sz)\n",
    "        dot_prods = torch.einsum(\"bkf,bf->bk\", embs, y)\n",
    "        return self._loss_func(dot_prods, torch.zeros(bs, dtype=torch.int64).to(y.device),\n",
    "                               mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sz = bert_config.hidden_size\n",
    "y = torch.randn((3, 7, emb_sz)).view((-1, emb_sz)).to(device)\n",
    "tgt = torch.randint(100, (3, 7, 50)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[39, 87, 76,  ..., 90, 45, 19],\n",
       "         [84, 92, 16,  ..., 38, 94, 94],\n",
       "         [40, 59, 97,  ..., 92, 60, 20],\n",
       "         ...,\n",
       "         [ 6, 28, 23,  ...,  6, 36, 13],\n",
       "         [35, 95, 22,  ..., 39,  0, 62],\n",
       "         [70, 38, 45,  ..., 95, 52, 43]],\n",
       "\n",
       "        [[81, 53, 80,  ..., 25, 11, 81],\n",
       "         [26, 34, 40,  ..., 29, 32, 82],\n",
       "         [36, 60, 61,  ..., 30, 90, 89],\n",
       "         ...,\n",
       "         [74, 84, 16,  ..., 30, 72, 29],\n",
       "         [98, 41, 66,  ..., 87, 99, 31],\n",
       "         [50, 47, 89,  ..., 50, 53, 24]],\n",
       "\n",
       "        [[41, 59, 60,  ..., 36, 67,  7],\n",
       "         [ 4, 43, 68,  ..., 88, 97, 17],\n",
       "         [96, 34, 44,  ..., 14, 83, 35],\n",
       "         ...,\n",
       "         [93, 28, 39,  ..., 59, 53, 12],\n",
       "         [24, 34,  4,  ..., 32, 19, 48],\n",
       "         [17, 95, 20,  ...,  6, 23, 68]]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.loss == \"is\":\n",
    "    loss = ImportanceSamplingCNNLoss(\n",
    "        output_embs, k=10, probs=torch.rand(100),\n",
    "    )\n",
    "    loss(y, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Masker(nn.Module):\n",
    "    def __init__(self, vocab: Vocabulary, \n",
    "                 noise_rate: float=config.mask_rate,\n",
    "                 mask_rate=1.0,\n",
    "                 replace_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.vocab_sz = vocab.get_vocab_size()\n",
    "        if config.char_encoder == \"cnn\":\n",
    "            self.mask_id = mask_char_ids.unsqueeze(0).unsqueeze(1)\n",
    "        else:\n",
    "            self.mask_id = vocab.get_token_index(\"[MASK]\")\n",
    "        self.noise_rate = noise_rate\n",
    "        self.mask_rate = mask_rate\n",
    "        self.replace_rate = replace_rate\n",
    "        \n",
    "    def create_mask(self, shape, ones_ratio, dtype=torch.uint8):\n",
    "        return (torch.ones(shape, dtype=dtype, \n",
    "                           requires_grad=False)\n",
    "                     .bernoulli(ones_ratio))\n",
    "\n",
    "    def get_random_input_ids(self, shape):\n",
    "        \"\"\"Returns randomly sampled \"\"\"\n",
    "        if config.char_encoder == \"cnn\":\n",
    "            rint = torch.randint(self.vocab_sz, shape)\n",
    "            return word_id_to_char_idxs[rint]\n",
    "        elif config.char_encoder == \"fasttext\" or config.char_encoder == \"subword\":\n",
    "            return torch.randint(self.vocab_sz, shape)\n",
    "\n",
    "    def forward(self, x: torch.LongTensor) -> torch.LongTensor:\n",
    "        char_level = len(x.shape) > 2 # using character-level features, but mask at word-level\n",
    "        if self.noise_rate > 0:\n",
    "            with torch.no_grad(): # no grads required here\n",
    "                mask_shape = x.shape[:-1] if char_level else x.shape\n",
    "                mask = self.create_mask(mask_shape, \n",
    "                                        self.noise_rate * self.mask_rate).to(x.device)\n",
    "                if config.char_encoder == \"cnn\":\n",
    "                    x = torch.where(mask.unsqueeze(2), self.mask_id, x)                \n",
    "                else:\n",
    "                    x = x.masked_fill(mask, self.mask_id)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "\n",
    "class MaskedLM(Model):\n",
    "    def __init__(self, vocab: Vocabulary, model: nn.Module,\n",
    "                loss: nn.Module, noise_rate=0.8):\n",
    "        super().__init__(vocab)\n",
    "        self.masker = Masker(vocab, noise_rate=noise_rate)\n",
    "        self.accuracy = CategoricalAccuracy()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "    \n",
    "    @property\n",
    "    def outputs_logits(self) -> bool:\n",
    "        return self.model[-1].output_logits\n",
    "    \n",
    "    def forward(self, input: TensorDict, \n",
    "                output: TensorDict, **kwargs) -> TensorDict:\n",
    "        mask = get_text_field_mask(input).to(device)\n",
    "        x = self.masker(input[\"tokens\"])\n",
    "        tgt = output[\"tokens\"].to(device)\n",
    "        \n",
    "        logits = self.model(x)\n",
    "        out_dict = {\"loss\": self.loss(logits, tgt, mask=mask)}\n",
    "        out_dict[\"logits\"] = logits\n",
    "        if self.outputs_logits:\n",
    "            out_dict[\"accuracy\"] = self.accuracy(logits, tgt)\n",
    "        return out_dict\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        if self.outputs_logits:\n",
    "            return {\"accuracy\": self.accuracy.get_metric(reset)}\n",
    "        else:\n",
    "            return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.loss == \"masked_crossentropy\":\n",
    "    loss = MaskedCrossEntropyLoss()\n",
    "elif config.loss == \"crossentropy\":\n",
    "    _loss = nn.CrossEntropyLoss()\n",
    "    def ce(y, t, mask=None): \n",
    "        return _loss(y.view((-1, y.size(-1))), t.view((-1, )))\n",
    "    loss = ce\n",
    "elif config.loss == \"is\":\n",
    "    if config.softmax == \"cnn_softmax\":\n",
    "        loss = ImportanceSamplingCNNLoss(output_embs, freqs)\n",
    "    else:# TODO: Implement masking\n",
    "        loss = ImportanceSamplingLoss(output_embs, freqs)\n",
    "else:\n",
    "    raise ValueError(\"AAAAAAAAAAAAA\")\n",
    "masked_lm = MaskedLM(vocab, custom_model, loss, noise_rate=0.15)\n",
    "if torch.cuda.is_available(): masked_lm.cuda() # Is this different from to(device)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(masked_lm.state_dict(), DATA_ROOT / \"masked_lm_tmp2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = nn_util.move_to_device(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = batch[\"input\"]\n",
    "output = batch[\"output\"]\n",
    "mask = get_text_field_mask(input).to(device)\n",
    "x = masked_lm.masker(input[\"tokens\"])\n",
    "tgt = output[\"tokens\"].to(device)\n",
    "\n",
    "logits = masked_lm.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8803e+00, -1.1189e+00,  3.8443e-01,  ..., -3.1873e-01,\n",
       "           5.9588e-01,  3.8869e-01],\n",
       "         [-3.4913e-01, -4.6801e-01, -1.1681e+00,  ..., -1.2559e+00,\n",
       "           1.6917e+00,  8.2842e-01],\n",
       "         [ 5.6573e-01, -1.6289e+00, -1.1664e+00,  ..., -6.6965e-01,\n",
       "           7.6219e-01, -1.2412e+00],\n",
       "         ...,\n",
       "         [ 5.0758e-01, -1.5967e+00, -8.9374e-01,  ..., -1.3117e+00,\n",
       "           8.4707e-01, -2.8985e-01],\n",
       "         [-1.6587e+00, -9.1444e-01, -6.7633e-02,  ...,  3.6648e-01,\n",
       "           5.6736e-01, -8.1231e-01],\n",
       "         [ 1.0118e+00, -2.8515e+00, -1.1834e+00,  ...,  9.1839e-01,\n",
       "           8.8668e-01,  3.9653e-01]],\n",
       "\n",
       "        [[ 1.0310e+00, -1.2212e+00, -3.2921e-01,  ..., -9.9011e-01,\n",
       "           8.0284e-01, -1.0964e-01],\n",
       "         [-1.5519e+00, -2.9082e-01, -1.0774e+00,  ..., -1.1716e+00,\n",
       "           1.7685e+00,  6.5217e-01],\n",
       "         [ 1.0063e+00, -2.3794e+00, -1.2714e+00,  ..., -4.5537e-01,\n",
       "           4.2940e-01, -7.8346e-01],\n",
       "         ...,\n",
       "         [ 3.0946e-01, -1.1875e+00, -1.4189e+00,  ..., -1.7828e+00,\n",
       "           9.8718e-01, -9.2339e-01],\n",
       "         [-1.5100e+00, -5.3549e-01,  8.7257e-01,  ..., -1.7776e-01,\n",
       "           2.2470e+00, -2.0645e+00],\n",
       "         [ 8.1397e-01, -1.2142e+00, -2.2075e+00,  ...,  5.3467e-02,\n",
       "           3.8077e-01, -3.2686e-01]],\n",
       "\n",
       "        [[ 1.2652e+00, -1.8628e+00,  2.1629e-01,  ..., -6.5429e-01,\n",
       "           1.1769e+00, -2.1301e-03],\n",
       "         [-7.3389e-01, -3.9118e-01, -1.1110e+00,  ..., -1.6314e+00,\n",
       "           1.7641e+00,  1.2915e+00],\n",
       "         [ 6.5439e-01, -1.7664e+00,  5.6184e-02,  ..., -3.6352e-01,\n",
       "          -4.6067e-01,  2.5409e-01],\n",
       "         ...,\n",
       "         [ 6.4084e-01, -1.0819e+00, -1.4468e+00,  ..., -1.6557e+00,\n",
       "           8.9486e-01, -1.6723e-01],\n",
       "         [-1.6306e+00, -3.8522e-01,  5.0367e-01,  ..., -3.9499e-01,\n",
       "           1.4013e+00, -1.7756e+00],\n",
       "         [ 1.3679e+00, -2.6980e+00, -2.1167e+00,  ...,  5.6249e-01,\n",
       "           5.2709e-01,  4.6491e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.5366e+00, -1.5468e+00, -2.1567e-01,  ..., -8.3154e-01,\n",
       "           1.4191e+00, -4.0646e-01],\n",
       "         [-3.1400e-01,  1.3914e-02, -1.3560e+00,  ..., -1.8063e+00,\n",
       "           2.4463e+00,  5.3902e-01],\n",
       "         [ 1.5855e-01, -2.0168e+00, -1.2696e+00,  ..., -9.4132e-01,\n",
       "          -3.3573e-02, -6.2249e-01],\n",
       "         ...,\n",
       "         [ 5.6329e-01, -7.6142e-01, -1.7986e+00,  ..., -2.6210e+00,\n",
       "           1.3932e+00, -6.4866e-01],\n",
       "         [-1.9890e+00, -1.3296e+00, -1.0630e+00,  ...,  1.1675e-01,\n",
       "           8.0983e-01, -1.4335e+00],\n",
       "         [ 1.1244e+00, -2.2171e+00, -2.0761e+00,  ...,  7.5641e-01,\n",
       "          -4.1821e-01, -2.6820e-01]],\n",
       "\n",
       "        [[ 7.0140e-01, -1.9362e+00, -3.6263e-02,  ..., -8.6769e-01,\n",
       "           7.7184e-01, -4.0646e-01],\n",
       "         [-7.2052e-01, -1.3818e-01, -1.0046e+00,  ..., -1.5763e+00,\n",
       "           1.7120e+00,  9.0456e-01],\n",
       "         [-2.5642e-01, -9.3303e-01, -1.3545e+00,  ..., -3.6420e-01,\n",
       "           1.2168e-01, -7.5141e-01],\n",
       "         ...,\n",
       "         [-1.0856e+00, -5.5445e-02,  4.3412e-01,  ..., -7.1988e-01,\n",
       "           1.6316e+00, -1.6994e+00],\n",
       "         [-1.7957e+00, -1.0285e+00, -1.6048e-01,  ...,  4.5546e-01,\n",
       "           6.7797e-01, -9.6194e-01],\n",
       "         [ 8.4106e-01, -7.2691e-01, -2.1034e+00,  ...,  5.4770e-01,\n",
       "           2.7110e-01, -9.8318e-01]],\n",
       "\n",
       "        [[ 1.1619e+00, -1.7603e+00,  1.4138e-02,  ..., -1.5737e+00,\n",
       "           1.3900e+00, -1.7586e-01],\n",
       "         [-6.2551e-01,  6.3928e-02, -1.0235e+00,  ..., -7.9265e-01,\n",
       "           1.4254e+00,  1.5825e+00],\n",
       "         [-1.9513e-01, -1.2280e+00, -1.1698e+00,  ..., -4.2450e-01,\n",
       "           5.3397e-01, -7.2857e-01],\n",
       "         ...,\n",
       "         [-7.6811e-03, -6.3604e-01, -1.1342e+00,  ..., -5.0870e-01,\n",
       "           8.2823e-01, -7.0824e-01],\n",
       "         [-1.6591e+00, -4.9098e-01, -1.6024e+00,  ..., -4.0488e-01,\n",
       "           1.2244e+00, -2.1484e+00],\n",
       "         [ 1.4801e+00, -2.0608e+00, -2.1046e+00,  ...,  1.1938e+00,\n",
       "           7.6178e-01, -4.1336e-01]]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = logits\n",
    "if len(y.shape) > 2:            \n",
    "    y = y.view((-1, y.size(-1))) # (batch * seq, emb_sz)\n",
    "bs, emb_sz = y.size(0), y.size(1)\n",
    "pos_embeddings = loss.get_embeddings(tgt, lookup_char_idxs=False).view(bs, -1) # (bs, emb_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1372,  0.0569, -0.2525,  ...,  0.0218, -0.1455, -0.0987],\n",
       "        [ 0.0607, -0.5274, -0.3160,  ...,  0.5322,  0.2186, -0.1910],\n",
       "        [ 0.4555,  0.4182, -0.9137,  ...,  0.0938,  0.0448, -0.2436],\n",
       "        ...,\n",
       "        [ 0.2326, -0.5339, -0.0772,  ...,  0.4814, -0.0768, -0.1773],\n",
       "        [ 0.4555,  0.4182, -0.9137,  ...,  0.0938,  0.0448, -0.2436],\n",
       "        [ 0.0492, -0.0012, -0.2530,  ...,  0.2310, -0.2063, -0.0053]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share negative samples across the batch\n",
    "neg_samples = (loss.get_negative_samples()\n",
    "               .to(y.device)) # (k, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  245,   523, 37057,  ...,  2793,  4597, 54890], device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(98015, device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_samples.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98251, 50])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_id_to_char_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_embeddings = loss.get_embeddings(neg_samples) # (k, emb_sz)\n",
    "embs = torch.cat([\n",
    "    pos_embeddings.unsqueeze(1), # (bs, 1, emb_sz)\n",
    "    neg_embeddings.unsqueeze(0).expand(bs, loss.k, emb_sz) # (bs, k, emb_sz)\n",
    "], dim=1) # (bs, k+1, emb_sz)\n",
    "dot_prods = torch.einsum(\"bkf,bf->bk\", embs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8803e+00, -1.1189e+00,  3.8443e-01,  ..., -3.1873e-01,\n",
       "           5.9588e-01,  3.8869e-01],\n",
       "         [-3.4913e-01, -4.6801e-01, -1.1681e+00,  ..., -1.2559e+00,\n",
       "           1.6917e+00,  8.2842e-01],\n",
       "         [ 5.6573e-01, -1.6289e+00, -1.1664e+00,  ..., -6.6965e-01,\n",
       "           7.6219e-01, -1.2412e+00],\n",
       "         ...,\n",
       "         [ 5.0758e-01, -1.5967e+00, -8.9374e-01,  ..., -1.3117e+00,\n",
       "           8.4707e-01, -2.8985e-01],\n",
       "         [-1.6587e+00, -9.1444e-01, -6.7633e-02,  ...,  3.6648e-01,\n",
       "           5.6736e-01, -8.1231e-01],\n",
       "         [ 1.0118e+00, -2.8515e+00, -1.1834e+00,  ...,  9.1839e-01,\n",
       "           8.8668e-01,  3.9653e-01]],\n",
       "\n",
       "        [[ 1.0310e+00, -1.2212e+00, -3.2921e-01,  ..., -9.9011e-01,\n",
       "           8.0284e-01, -1.0964e-01],\n",
       "         [-1.5519e+00, -2.9082e-01, -1.0774e+00,  ..., -1.1716e+00,\n",
       "           1.7685e+00,  6.5217e-01],\n",
       "         [ 1.0063e+00, -2.3794e+00, -1.2714e+00,  ..., -4.5537e-01,\n",
       "           4.2940e-01, -7.8346e-01],\n",
       "         ...,\n",
       "         [ 3.0946e-01, -1.1875e+00, -1.4189e+00,  ..., -1.7828e+00,\n",
       "           9.8718e-01, -9.2339e-01],\n",
       "         [-1.5100e+00, -5.3549e-01,  8.7257e-01,  ..., -1.7776e-01,\n",
       "           2.2470e+00, -2.0645e+00],\n",
       "         [ 8.1397e-01, -1.2142e+00, -2.2075e+00,  ...,  5.3467e-02,\n",
       "           3.8077e-01, -3.2686e-01]],\n",
       "\n",
       "        [[ 1.2652e+00, -1.8628e+00,  2.1629e-01,  ..., -6.5429e-01,\n",
       "           1.1769e+00, -2.1301e-03],\n",
       "         [-7.3389e-01, -3.9118e-01, -1.1110e+00,  ..., -1.6314e+00,\n",
       "           1.7641e+00,  1.2915e+00],\n",
       "         [ 6.5439e-01, -1.7664e+00,  5.6184e-02,  ..., -3.6352e-01,\n",
       "          -4.6067e-01,  2.5409e-01],\n",
       "         ...,\n",
       "         [ 6.4084e-01, -1.0819e+00, -1.4468e+00,  ..., -1.6557e+00,\n",
       "           8.9486e-01, -1.6723e-01],\n",
       "         [-1.6306e+00, -3.8522e-01,  5.0367e-01,  ..., -3.9499e-01,\n",
       "           1.4013e+00, -1.7756e+00],\n",
       "         [ 1.3679e+00, -2.6980e+00, -2.1167e+00,  ...,  5.6249e-01,\n",
       "           5.2709e-01,  4.6491e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.5366e+00, -1.5468e+00, -2.1567e-01,  ..., -8.3154e-01,\n",
       "           1.4191e+00, -4.0646e-01],\n",
       "         [-3.1400e-01,  1.3914e-02, -1.3560e+00,  ..., -1.8063e+00,\n",
       "           2.4463e+00,  5.3902e-01],\n",
       "         [ 1.5855e-01, -2.0168e+00, -1.2696e+00,  ..., -9.4132e-01,\n",
       "          -3.3573e-02, -6.2249e-01],\n",
       "         ...,\n",
       "         [ 5.6329e-01, -7.6142e-01, -1.7986e+00,  ..., -2.6210e+00,\n",
       "           1.3932e+00, -6.4866e-01],\n",
       "         [-1.9890e+00, -1.3296e+00, -1.0630e+00,  ...,  1.1675e-01,\n",
       "           8.0983e-01, -1.4335e+00],\n",
       "         [ 1.1244e+00, -2.2171e+00, -2.0761e+00,  ...,  7.5641e-01,\n",
       "          -4.1821e-01, -2.6820e-01]],\n",
       "\n",
       "        [[ 7.0140e-01, -1.9362e+00, -3.6263e-02,  ..., -8.6769e-01,\n",
       "           7.7184e-01, -4.0646e-01],\n",
       "         [-7.2052e-01, -1.3818e-01, -1.0046e+00,  ..., -1.5763e+00,\n",
       "           1.7120e+00,  9.0456e-01],\n",
       "         [-2.5642e-01, -9.3303e-01, -1.3545e+00,  ..., -3.6420e-01,\n",
       "           1.2168e-01, -7.5141e-01],\n",
       "         ...,\n",
       "         [-1.0856e+00, -5.5445e-02,  4.3412e-01,  ..., -7.1988e-01,\n",
       "           1.6316e+00, -1.6994e+00],\n",
       "         [-1.7957e+00, -1.0285e+00, -1.6048e-01,  ...,  4.5546e-01,\n",
       "           6.7797e-01, -9.6194e-01],\n",
       "         [ 8.4106e-01, -7.2691e-01, -2.1034e+00,  ...,  5.4770e-01,\n",
       "           2.7110e-01, -9.8318e-01]],\n",
       "\n",
       "        [[ 1.1619e+00, -1.7603e+00,  1.4138e-02,  ..., -1.5737e+00,\n",
       "           1.3900e+00, -1.7586e-01],\n",
       "         [-6.2551e-01,  6.3928e-02, -1.0235e+00,  ..., -7.9265e-01,\n",
       "           1.4254e+00,  1.5825e+00],\n",
       "         [-1.9513e-01, -1.2280e+00, -1.1698e+00,  ..., -4.2450e-01,\n",
       "           5.3397e-01, -7.2857e-01],\n",
       "         ...,\n",
       "         [-7.6811e-03, -6.3604e-01, -1.1342e+00,  ..., -5.0870e-01,\n",
       "           8.2823e-01, -7.0824e-01],\n",
       "         [-1.6591e+00, -4.9098e-01, -1.6024e+00,  ..., -4.0488e-01,\n",
       "           1.2244e+00, -2.1484e+00],\n",
       "         [ 1.4801e+00, -2.0608e+00, -2.1046e+00,  ...,  1.1938e+00,\n",
       "           7.6178e-01, -4.1336e-01]]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm.masker.noise_rate = 0.05 if config.denoise else 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1372,  0.0569, -0.2525,  ...,  0.0218, -0.1455, -0.0987],\n",
       "        [ 0.0607, -0.5274, -0.3160,  ...,  0.5322,  0.2186, -0.1910],\n",
       "        [ 0.4555,  0.4182, -0.9137,  ...,  0.0938,  0.0448, -0.2436],\n",
       "        ...,\n",
       "        [ 0.2326, -0.5339, -0.0772,  ...,  0.4814, -0.0768, -0.1773],\n",
       "        [ 0.4555,  0.4182, -0.9137,  ...,  0.0938,  0.0448, -0.2436],\n",
       "        [ 0.0492, -0.0012, -0.2530,  ...,  0.2310, -0.2063, -0.0053]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.testing:\n",
    "    batch = nn_util.move_to_device(batch, 0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "#     tokens = masked_lm.masker(batch[\"input\"][\"tokens\"])\n",
    "\n",
    "#     hidden_states = masked_lm.model[:2](tokens)\n",
    "\n",
    "#     masked_lm.model[2](hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.testing: masked_lm(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_embeddings = loss.get_embeddings(neg_samples) # (k, emb_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ImportanceSamplingCNNLoss.get_embeddings of ImportanceSamplingCNNLoss(\n",
       "  (embedding_generator): ElmoDecoder(\n",
       "    (_enc): ElmoEncoder(\n",
       "      (_inner): _ElmoCharacterEncoder(\n",
       "        (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "        (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "        (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "        (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "        (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "        (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "        (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "        (_highways): Highway(\n",
       "          (_layers): ModuleList(\n",
       "            (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_projection): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (_dec): Linear(in_features=128, out_features=128, bias=False)\n",
       "  )\n",
       "  (_loss_func): MaskedCrossEntropyLoss(\n",
       "    (_loss): CrossEntropyLoss()\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.get_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingWPositionEmbs(\n",
       "  (word_emb): ElmoEncoder(\n",
       "    (_inner): _ElmoCharacterEncoder(\n",
       "      (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "      (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "      (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "      (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "      (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "      (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "      (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "      (_highways): Highway(\n",
       "        (_layers): ModuleList(\n",
       "          (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_projection): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (position_embeddings): Embedding(128, 128)\n",
       "  (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "  (norm): LayerNorm()\n",
       "  (do): Dropout(p=0.1)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElmoDecoder(\n",
       "  (_enc): ElmoEncoder(\n",
       "    (_inner): _ElmoCharacterEncoder(\n",
       "      (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "      (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "      (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "      (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "      (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "      (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "      (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "      (_highways): Highway(\n",
       "        (_layers): ModuleList(\n",
       "          (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_projection): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_dec): Linear(in_features=128, out_features=128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2023, -0.6875, -0.2014,  ...,  0.2349, -0.1344, -0.1402],\n",
       "        [-0.7778, -0.0124,  0.6745,  ..., -0.2378, -0.0466, -0.1360],\n",
       "        [-0.1739,  0.2081, -0.0993,  ...,  0.1709, -0.2481, -0.0325],\n",
       "        ...,\n",
       "        [-0.2379, -0.6720,  0.2089,  ...,  0.4555, -0.1540,  0.0879],\n",
       "        [-0.2309,  0.0147, -0.1290,  ...,  0.1137, -0.5712,  0.3739],\n",
       "        [ 0.2628, -0.2134,  0.0961,  ...,  0.2700, -0.3750,  0.1704]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.cat([\n",
    "    pos_embeddings.unsqueeze(1), # (bs, 1, emb_sz)\n",
    "    neg_embeddings.unsqueeze(0).expand(bs, loss.k, emb_sz) # (bs, k, emb_sz)\n",
    "], dim=1) # (bs, k+1, emb_sz)\n",
    "dot_prods = torch.einsum(\"bkf,bf->bk\", embs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImportanceSamplingCNNLoss(\n",
       "  (embedding_generator): ElmoDecoder(\n",
       "    (_enc): ElmoEncoder(\n",
       "      (_inner): _ElmoCharacterEncoder(\n",
       "        (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "        (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "        (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "        (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "        (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "        (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "        (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "        (_highways): Highway(\n",
       "          (_layers): ModuleList(\n",
       "            (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_projection): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (_dec): Linear(in_features=128, out_features=128, bias=False)\n",
       "  )\n",
       "  (_loss_func): MaskedCrossEntropyLoss(\n",
       "    (_loss): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training import Callback\n",
    "import gc\n",
    "\n",
    "class GCCallback(Callback):\n",
    "    \"\"\"Calls gc periodically to prevent memory errors\"\"\"\n",
    "    def __init__(self, period: int=10000):\n",
    "        self._period = period\n",
    "        \n",
    "    def on_batch_end(self, data):\n",
    "        if (data[\"batches_this_epoch\"] + 1) % self._period == 0:\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training import Trainer, TrainerWithCallbacks\n",
    "\n",
    "optimizer = torch.optim.Adam(masked_lm.parameters(), lr=config.lr)\n",
    "SER_DIR = (DATA_ROOT / \"bert_ckpts_cnn_denoise_is_cnnsoftmax\") if not config.testing else None\n",
    "cdevice = 0 if torch.cuda.is_available() and (config.char_encoder != \"subword\" or config.put_embeddings_on_gpu) else -1\n",
    "\n",
    "# trainer = TrainerWithCallbacks(\n",
    "#     model=masked_lm,\n",
    "#     optimizer=optimizer,\n",
    "#     iterator=iterator,\n",
    "#     train_dataset=train_ds,\n",
    "#     validation_dataset=val_ds,\n",
    "#     gradient_accumulation_steps=config.batch_size // config.computational_batch_size,\n",
    "#     serialization_dir=SER_DIR,\n",
    "#     cuda_device=cdevice,\n",
    "#     patience=1,\n",
    "#     num_epochs=config.epochs,\n",
    "#     grad_clipping=5.,\n",
    "#     callbacks=[GCCallback()],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_lm.load_state_dict(torch.load(DATA_ROOT / \"masked_lm_tmp2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_state_dict = torch.load(DATA_ROOT / \"..\" / \"jigsaw\" / \"bert_ckpts_cnn_sm_denoise_is_tst_2\" / \"best.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['model.0.embeddings.word_emb._inner._char_embedding_weights', 'model.0.embeddings.word_emb._inner.char_conv_0.weight', 'model.0.embeddings.word_emb._inner.char_conv_0.bias', 'model.0.embeddings.word_emb._inner.char_conv_1.weight', 'model.0.embeddings.word_emb._inner.char_conv_1.bias', 'model.0.embeddings.word_emb._inner.char_conv_2.weight', 'model.0.embeddings.word_emb._inner.char_conv_2.bias', 'model.0.embeddings.word_emb._inner.char_conv_3.weight', 'model.0.embeddings.word_emb._inner.char_conv_3.bias', 'model.0.embeddings.word_emb._inner.char_conv_4.weight', 'model.0.embeddings.word_emb._inner.char_conv_4.bias', 'model.0.embeddings.word_emb._inner.char_conv_5.weight', 'model.0.embeddings.word_emb._inner.char_conv_5.bias', 'model.0.embeddings.word_emb._inner.char_conv_6.weight', 'model.0.embeddings.word_emb._inner.char_conv_6.bias', 'model.0.embeddings.word_emb._inner._highways._layers.0.weight', 'model.0.embeddings.word_emb._inner._highways._layers.0.bias', 'model.0.embeddings.word_emb._inner._projection.weight', 'model.0.embeddings.word_emb._inner._projection.bias', 'model.0.embeddings.position_embeddings.weight', 'model.0.embeddings.linear.weight', 'model.0.embeddings.norm.weight', 'model.0.embeddings.norm.bias', 'model.0.encoder.layer.0.attention.self.query.weight', 'model.0.encoder.layer.0.attention.self.query.bias', 'model.0.encoder.layer.0.attention.self.key.weight', 'model.0.encoder.layer.0.attention.self.key.bias', 'model.0.encoder.layer.0.attention.self.value.weight', 'model.0.encoder.layer.0.attention.self.value.bias', 'model.0.encoder.layer.0.attention.output.dense.weight', 'model.0.encoder.layer.0.attention.output.dense.bias', 'model.0.encoder.layer.0.attention.output.LayerNorm.weight', 'model.0.encoder.layer.0.attention.output.LayerNorm.bias', 'model.0.encoder.layer.0.intermediate.dense.weight', 'model.0.encoder.layer.0.intermediate.dense.bias', 'model.0.encoder.layer.0.output.dense.weight', 'model.0.encoder.layer.0.output.dense.bias', 'model.0.encoder.layer.0.output.LayerNorm.weight', 'model.0.encoder.layer.0.output.LayerNorm.bias', 'model.0.encoder.layer.1.attention.self.query.weight', 'model.0.encoder.layer.1.attention.self.query.bias', 'model.0.encoder.layer.1.attention.self.key.weight', 'model.0.encoder.layer.1.attention.self.key.bias', 'model.0.encoder.layer.1.attention.self.value.weight', 'model.0.encoder.layer.1.attention.self.value.bias', 'model.0.encoder.layer.1.attention.output.dense.weight', 'model.0.encoder.layer.1.attention.output.dense.bias', 'model.0.encoder.layer.1.attention.output.LayerNorm.weight', 'model.0.encoder.layer.1.attention.output.LayerNorm.bias', 'model.0.encoder.layer.1.intermediate.dense.weight', 'model.0.encoder.layer.1.intermediate.dense.bias', 'model.0.encoder.layer.1.output.dense.weight', 'model.0.encoder.layer.1.output.dense.bias', 'model.0.encoder.layer.1.output.LayerNorm.weight', 'model.0.encoder.layer.1.output.LayerNorm.bias', 'model.0.encoder.layer.2.attention.self.query.weight', 'model.0.encoder.layer.2.attention.self.query.bias', 'model.0.encoder.layer.2.attention.self.key.weight', 'model.0.encoder.layer.2.attention.self.key.bias', 'model.0.encoder.layer.2.attention.self.value.weight', 'model.0.encoder.layer.2.attention.self.value.bias', 'model.0.encoder.layer.2.attention.output.dense.weight', 'model.0.encoder.layer.2.attention.output.dense.bias', 'model.0.encoder.layer.2.attention.output.LayerNorm.weight', 'model.0.encoder.layer.2.attention.output.LayerNorm.bias', 'model.0.encoder.layer.2.intermediate.dense.weight', 'model.0.encoder.layer.2.intermediate.dense.bias', 'model.0.encoder.layer.2.output.dense.weight', 'model.0.encoder.layer.2.output.dense.bias', 'model.0.encoder.layer.2.output.LayerNorm.weight', 'model.0.encoder.layer.2.output.LayerNorm.bias', 'model.0.encoder.layer.3.attention.self.query.weight', 'model.0.encoder.layer.3.attention.self.query.bias', 'model.0.encoder.layer.3.attention.self.key.weight', 'model.0.encoder.layer.3.attention.self.key.bias', 'model.0.encoder.layer.3.attention.self.value.weight', 'model.0.encoder.layer.3.attention.self.value.bias', 'model.0.encoder.layer.3.attention.output.dense.weight', 'model.0.encoder.layer.3.attention.output.dense.bias', 'model.0.encoder.layer.3.attention.output.LayerNorm.weight', 'model.0.encoder.layer.3.attention.output.LayerNorm.bias', 'model.0.encoder.layer.3.intermediate.dense.weight', 'model.0.encoder.layer.3.intermediate.dense.bias', 'model.0.encoder.layer.3.output.dense.weight', 'model.0.encoder.layer.3.output.dense.bias', 'model.0.encoder.layer.3.output.LayerNorm.weight', 'model.0.encoder.layer.3.output.LayerNorm.bias', 'model.0.encoder.layer.4.attention.self.query.weight', 'model.0.encoder.layer.4.attention.self.query.bias', 'model.0.encoder.layer.4.attention.self.key.weight', 'model.0.encoder.layer.4.attention.self.key.bias', 'model.0.encoder.layer.4.attention.self.value.weight', 'model.0.encoder.layer.4.attention.self.value.bias', 'model.0.encoder.layer.4.attention.output.dense.weight', 'model.0.encoder.layer.4.attention.output.dense.bias', 'model.0.encoder.layer.4.attention.output.LayerNorm.weight', 'model.0.encoder.layer.4.attention.output.LayerNorm.bias', 'model.0.encoder.layer.4.intermediate.dense.weight', 'model.0.encoder.layer.4.intermediate.dense.bias', 'model.0.encoder.layer.4.output.dense.weight', 'model.0.encoder.layer.4.output.dense.bias', 'model.0.encoder.layer.4.output.LayerNorm.weight', 'model.0.encoder.layer.4.output.LayerNorm.bias', 'model.0.encoder.layer.5.attention.self.query.weight', 'model.0.encoder.layer.5.attention.self.query.bias', 'model.0.encoder.layer.5.attention.self.key.weight', 'model.0.encoder.layer.5.attention.self.key.bias', 'model.0.encoder.layer.5.attention.self.value.weight', 'model.0.encoder.layer.5.attention.self.value.bias', 'model.0.encoder.layer.5.attention.output.dense.weight', 'model.0.encoder.layer.5.attention.output.dense.bias', 'model.0.encoder.layer.5.attention.output.LayerNorm.weight', 'model.0.encoder.layer.5.attention.output.LayerNorm.bias', 'model.0.encoder.layer.5.intermediate.dense.weight', 'model.0.encoder.layer.5.intermediate.dense.bias', 'model.0.encoder.layer.5.output.dense.weight', 'model.0.encoder.layer.5.output.dense.bias', 'model.0.encoder.layer.5.output.LayerNorm.weight', 'model.0.encoder.layer.5.output.LayerNorm.bias', 'model.2.dense.weight', 'model.2.dense.bias', 'model.2.LayerNorm.weight', 'model.2.LayerNorm.bias', 'loss.embedding_generator._enc._inner._char_embedding_weights', 'loss.embedding_generator._enc._inner.char_conv_0.weight', 'loss.embedding_generator._enc._inner.char_conv_0.bias', 'loss.embedding_generator._enc._inner.char_conv_1.weight', 'loss.embedding_generator._enc._inner.char_conv_1.bias', 'loss.embedding_generator._enc._inner.char_conv_2.weight', 'loss.embedding_generator._enc._inner.char_conv_2.bias', 'loss.embedding_generator._enc._inner.char_conv_3.weight', 'loss.embedding_generator._enc._inner.char_conv_3.bias', 'loss.embedding_generator._enc._inner.char_conv_4.weight', 'loss.embedding_generator._enc._inner.char_conv_4.bias', 'loss.embedding_generator._enc._inner.char_conv_5.weight', 'loss.embedding_generator._enc._inner.char_conv_5.bias', 'loss.embedding_generator._enc._inner.char_conv_6.weight', 'loss.embedding_generator._enc._inner.char_conv_6.bias', 'loss.embedding_generator._enc._inner._highways._layers.0.weight', 'loss.embedding_generator._enc._inner._highways._layers.0.bias', 'loss.embedding_generator._enc._inner._projection.weight', 'loss.embedding_generator._enc._inner._projection.bias', 'loss.embedding_generator._dec.weight'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parital_state_dict(model, dct):\n",
    "    added_params = set()\n",
    "    non_added_params = set()\n",
    "    for name, param in model.state_dict().items():\n",
    "        if name in dct:\n",
    "            try:\n",
    "                param.data.copy_(dct[name])\n",
    "                added_params.add(name)\n",
    "            except:\n",
    "                warnings.warn(f\"Failed to load {name} even though key exists\")\n",
    "                non_added_params.add(name)\n",
    "        else: non_added_params.add(name)\n",
    "    return non_added_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_parital_state_dict(masked_lm, tmp_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "SER_DIR = (DATA_ROOT / \"bert_ckpts_cnn_denoise_is_cnnsoftmax\") if not config.testing else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm.load_state_dict(torch.load(SER_DIR / \"best.th\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerWithCallbacks(\n",
    "    model=masked_lm,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    validation_dataset=val_ds,\n",
    "    gradient_accumulation_steps=config.batch_size // config.computational_batch_size,\n",
    "    serialization_dir=SER_DIR,\n",
    "    cuda_device=cdevice,\n",
    "    patience=1,\n",
    "    num_epochs=5,\n",
    "    grad_clipping=5.,\n",
    "    callbacks=[GCCallback()],\n",
    "    deindex=True,\n",
    "    model_save_interval=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.9456 ||: : 11623it [51:17,  3.94it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9469 ||: : 41611it [3:00:54,  4.39it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9459 ||: : 54356it [3:54:46,  2.99it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9456 ||: : 69792it [5:07:01,  4.20it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9456 ||: : 82974it [6:01:20,  4.85it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9449 ||: : 96098it [6:55:24,  3.96it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9444 ||: : 109172it [7:49:25,  4.85it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9440 ||: : 122240it [8:43:21,  4.10it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9441 ||: : 135261it [9:36:29,  4.39it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9441 ||: : 148261it [10:29:33,  4.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9436 ||: : 161202it [11:22:09,  4.31it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9434 ||: : 174220it [12:17:24,  2.89it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9432 ||: : 187204it [13:18:17,  3.84it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9431 ||: : 200178it [14:18:08,  2.66it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9430 ||: : 213175it [15:15:55,  4.07it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9428 ||: : 226160it [16:08:34,  3.77it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9427 ||: : 239153it [17:02:26,  4.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9426 ||: : 252172it [17:56:22,  3.65it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9429 ||: : 265156it [18:50:25,  4.15it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9429 ||: : 306930it [22:08:10,  2.77it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9429 ||: : 319830it [23:08:34,  3.80it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9428 ||: : 332767it [24:04:05,  3.05it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.9426 ||: : 345727it [25:07:22,  2.74it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9426 ||: : 358680it [26:03:59,  4.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9425 ||: : 371641it [26:56:57,  3.62it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9424 ||: : 384503it [27:49:11,  4.29it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9422 ||: : 397379it [28:41:33,  3.73it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9421 ||: : 410251it [29:33:58,  4.38it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9421 ||: : 423215it [30:26:39,  4.33it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9421 ||: : 436075it [31:18:56,  4.10it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9419 ||: : 448978it [32:11:16,  3.49it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9420 ||: : 461860it [33:04:26,  3.73it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9419 ||: : 474752it [33:57:47,  4.58it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9419 ||: : 487692it [34:51:38,  4.23it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9420 ||: : 500658it [35:45:03,  4.38it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9420 ||: : 513600it [36:37:59,  3.71it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9419 ||: : 526607it [37:31:01,  4.10it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.9419 ||: : 528429it [37:40:28,  3.20it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-3613d6448b3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/master/lib/python3.7/site-packages/allennlp/training/trainer_with_callbacks.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEventType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_END\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/master/lib/python3.7/site-packages/allennlp/training/trainer_with_callbacks.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;31m# check for nan weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/master/lib/python3.7/site-packages/allennlp/training/trainer_with_callbacks.py\u001b[0m in \u001b[0;36mbatch_loss\u001b[0;34m(self, batch_group, for_training)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_group\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_devices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/master/lib/python3.7/site-packages/allennlp/nn/util.py\u001b[0m in \u001b[0;36mmove_to_device\u001b[0;34m(obj, cuda_device)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/master/lib/python3.7/site-packages/allennlp/nn/util.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/master/lib/python3.7/site-packages/allennlp/nn/util.py\u001b[0m in \u001b[0;36mmove_to_device\u001b[0;34m(obj, cuda_device)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/master/lib/python3.7/site-packages/allennlp/nn/util.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/master/lib/python3.7/site-packages/allennlp/nn/util.py\u001b[0m in \u001b[0;36mmove_to_device\u001b[0;34m(obj, cuda_device)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SER_DIR is not None:\n",
    "    torch.save(masked_lm.state_dict(), SER_DIR / \"best.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SER_DIR is not None:\n",
    "    masked_lm.load_state_dict(torch.load(SER_DIR / \"best.th\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = TrainerWithCallbacks(\n",
    "#     model=masked_lm,\n",
    "#     optimizer=optimizer,\n",
    "#     iterator=iterator,\n",
    "#     train_dataset=train_ds,\n",
    "#     validation_dataset=val_ds,\n",
    "#     gradient_accumulation_steps=config.batch_size // config.computational_batch_size,\n",
    "#     serialization_dir=SER_DIR,\n",
    "#     cuda_device=cdevice,\n",
    "#     patience=1,\n",
    "#     num_epochs=config.epochs + 5,\n",
    "#     grad_clipping=5.,\n",
    "#     callbacks=[GCCallback()],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cdevice = 0 if torch.cuda.is_available() and (config.char_encoder != \"subword\" or config.put_embeddings_on_gpu) else -1\n",
    "\n",
    "batch = nn_util.move_to_device(batch, cdevice)\n",
    "out_dict =masked_lm(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For IS loss, we need to aggregate the embeddings at the end of training to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# vocab_sz = vocab.get_vocab_size()\n",
    "# embedding_sz = bert_config.hidden_size\n",
    "\n",
    "# if config.loss == \"is\":\n",
    "#     bs = 1\n",
    "#     output_embedding_matrix = torch.zeros(vocab_sz, embedding_sz)\n",
    "#     num_batches = math.ceil(vocab_sz / bs)\n",
    "#     for i in range(num_batches):\n",
    "#         start,end = i*bs, min(((i+1)*bs), vocab_sz)\n",
    "#         idxs = torch.arange(start=start, end=end).unsqueeze(0)\n",
    "#         output_embedding_matrix[start:end, :] = loss.get_embeddings(idxs.to(device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Check Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Implement manual checks for negative sampling loss as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(t): return t.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(arr):\n",
    "    if len(arr.shape) > 1:\n",
    "        return [to_words(a) for a in arr]\n",
    "    else:\n",
    "        arr = to_np(arr)\n",
    "        return \" \".join([vocab.get_token_from_index(i) for i in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, batch: TensorDict):\n",
    "    if config.loss == \"is\":\n",
    "        logits = model(**batch)[\"logits\"].cpu()\n",
    "        return (logits @ output_embedding_matrix.transpose(0, 1)).argmax(2)\n",
    "    else:\n",
    "        return model(**batch)[\"logits\"].argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm(**batch)[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cstm_pprint(x):\n",
    "    s = \"\\n\\n\".join(x)\n",
    "    print(s)\n",
    "    with open(SER_DIR / \"outputs.txt\", \"at\") as f:\n",
    "        f.write(s + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstm_pprint(to_words(batch[\"output\"][\"tokens\"])[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstm_pprint(to_words(get_preds(masked_lm, batch)[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debugging:\n",
    "    for i in range(3):\n",
    "        trainer = Trainer(\n",
    "            model=masked_lm,\n",
    "            optimizer=optimizer,\n",
    "            iterator=iterator,\n",
    "            train_dataset=train_ds,\n",
    "            validation_dataset=val_ds,\n",
    "            serialization_dir=SER_DIR,\n",
    "            cuda_device=0 if torch.cuda.is_available() else -1,\n",
    "            num_epochs=1,\n",
    "        )\n",
    "        trainer.train()\n",
    "        cstm_pprint(to_words(get_preds(masked_lm, batch))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstm_pprint(to_words(get_preds(masked_lm, batch))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm(**batch)[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
